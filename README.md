# Introduction

With rise of state-of-the-art AI tools, it is important for us to understand the Intiution and the math behind it and not just using the readily available APIs.

Below is how this repository is set up.

<br>


<br>

We will start with basics and then move to RNN, LSTM and Transformers. Hopefully it will help your NLP journey. 

Enjoy!!


# TOC


`learning path to be added - image to be added tomorrow`  
`add basics of arrays and matrix from Notion notes`    
`section on input shape of each of the architecture covered here`  
`code section should have all py file or ipynb file or maybe dagshub?`  

# Learning Path

  Diagram goes here


# Details

- Arrays, Matrix & Tensors

- Simple Neural Network
   * understand input and output shapes
   * simple program

- Simple RNN
   * understand input and output shapes
   * simple program

- LSTM
   * simple program


- Transformers
    * basics of attention model


# Basics

[Understanding Arrays, Matrix, Tensors](https://github.com/rvbug/NLP/tree/main/basics#understanding-arrays-matrix-tensors)


  

# Simple Neural Network
[Neural Network](https://github.com/rvbug/NLP/tree/main/simpleNN#simple-neural-network)

# RNN
[SimpleRNN](https://github.com/rvbug/NLP/tree/main/simpleRNN#simple-rnn)

# LSTM
[LSTM](https://github.com/rvbug/NLP/tree/main/simpleRNN#simple-rnn)

# Transformers & Attention
[Transformer](https://github.com/rvbug/NLP/tree/main/transformers)

# References
  - [TensorFlow](https://www.tensorflow.org/)
  - [Keras](https://keras.io/api/layers/)
  - [arXiv](https://arxiv.org/)  
  - [Paper with Code](https://paperswithcode.com/)  
  - [Kaggle](https://kaggle.com)
  - [LaTeX Reference](https://www.latex4technics.com/?note=GW021J)

# What's next
View My Quantum NLP Repo -  [QNLP ](https://github.com/rvbug/QuantumML)  
