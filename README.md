# Introduction

With rise of state-of-the-art AI tools, it is important for us to understand the Intiution and the math behind it and not just using the readily available APIs.

Below is how this repository is set up.

<br>
<img width="453" alt="image" src="https://github.com/rvbug/NLP/assets/10928536/774eb295-d903-4dbd-bf8e-ddbc633d53f3">

<br>
<br>

We will start with basics and then move to RNN, LSTM and finally Transformers which is basic building block of LLMs (Large Language Models). 

Enjoy!!


# Basics

[Understanding Arrays, Matrix, Tensors](https://github.com/rvbug/NLP/tree/main/basics#understanding-arrays-matrix-tensors)


# Simple Neural Network
[Neural Network](https://github.com/rvbug/NLP/tree/main/simpleNN#simple-neural-network)

# RNN
[SimpleRNN](https://github.com/rvbug/NLP/tree/main/simpleRNN#simple-rnn)

# LSTM
[LSTM](https://github.com/rvbug/NLP/tree/main/simpleRNN#simple-rnn)

# Transformers & Attention
[Transformer](https://github.com/rvbug/NLP/tree/main/transformers)

# References
  - [TensorFlow](https://www.tensorflow.org/)
  - [Keras](https://keras.io/api/layers/)
  - [arXiv](https://arxiv.org/)  
  - [Paper with Code](https://paperswithcode.com/)  
  - [Kaggle](https://kaggle.com)
  - [LaTeX Reference](https://www.latex4technics.com/?note=GW021J)


# What's next
Comming soon - Quantum NLP
