# Introduction

With rise of Large Language Models (LLMs) like GPT, it is important for us to understand Transformers. But to get there, you need to know the basics and this repo will guide you through that journey to help better understand the state-of-the-art AI tools. Enjoy!!

Below is how this repository is set up. 

<br>

<img width="303" alt="image" src="https://github.com/rvbug/NLP/assets/10928536/bd65c176-1499-4f5c-b3b4-61abe060a11b">

<br>
<br>





# Basics

[Understanding Arrays, Matrix, Tensors](https://github.com/rvbug/NLP/tree/main/basics#understanding-arrays-matrix-tensors)


# Simple Neural Network
[Neural Network](https://github.com/rvbug/NLP/tree/main/simpleNN#simple-neural-network)

# RNN
[SimpleRNN](https://github.com/rvbug/NLP/tree/main/simpleRNN#simple-rnn)

# LSTM
[LSTM](https://github.com/rvbug/NLP/tree/main/lstm)

# Transformers & Attention
[Transformer](https://github.com/rvbug/NLP/tree/main/transformers)

# References
  - [TensorFlow](https://www.tensorflow.org/)
  - [Keras](https://keras.io/api/layers/)
  - [arXiv](https://arxiv.org/)  
  - [Kaggle](https://kaggle.com)
  - [LaTeX Reference](https://www.latex4technics.com/?note=GW021J)


# What's next
Quantum ML (coming soon)
